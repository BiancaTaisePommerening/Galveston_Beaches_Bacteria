{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_set_up.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVE1eqfi35K9o9lUz0lYGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-garza/final_project/blob/bianca/spark_set_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Spark"
      ],
      "metadata": {
        "id": "laplqrCOkrxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY8cj8UpkmFn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "metadata": {
        "id": "GhSQ55iekvmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"FinalProject\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "1dxppfNik0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "snMnec_g8T7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles"
      ],
      "metadata": {
        "id": "WD5Xa6KZ8YeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bianca's path - Read beach_attributes from local gdrive location, MUST BE CHANGED TO MATCH YOUR FILE LOCATION!!!\n",
        "beach_attr_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"/content/drive/MyDrive/Data/Beach/Beach_Attributes.csv\"), header=True, inferSchema=True, timestampFormat=\"yyyy/MM/dd HH:mm:ss\")\n",
        "beach_attr_df.show()"
      ],
      "metadata": {
        "id": "NesYBKV18aFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect spark to a dataset from AWS S3 bucket.\n",
        "# from pyspark import SparkFiles\n",
        "# url = \"https://team-1-final-project-bucket.s3.amazonaws.com/water_quality_report.csv\"\n",
        "# spark.sparkContext.addFile(url)"
      ],
      "metadata": {
        "id": "xdUN0W37k30L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}